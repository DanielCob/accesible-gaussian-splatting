{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "466qCr2lLIB3"
      },
      "source": [
        "# Accessible Gaussian Splatting â€” Evaluation on Google Colab (T4)\n",
        "\n",
        "This notebook runs a non-interactive evaluation of the Accessible Gaussian Splatting pipeline on Tanks and Temples and Deep Blending datasets using a single 7k iteration point.\n",
        "\n",
        "- Datasets are assumed to be stored in Google Drive.\n",
        "- The notebook clones the repo, installs dependencies, runs training + rendering + metrics via `full_eval.py`.\n",
        "- A summary of metrics is produced and results are copied back to Drive for later comparison with baselines from the original paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYmE7z-fKngZ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrDl8Bmf2Il_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive and set dataset paths (update these if needed)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Root folders in Drive containing the datasets\n",
        "TAT_DIR = '/content/drive/MyDrive/tandt_db/tandt'\n",
        "DB_DIR  = '/content/drive/MyDrive/tandt_db/db'\n",
        "\n",
        "# Local output directory in Colab\n",
        "OUTPUT_DIR = '/content/accesible-gaussian-splatting/eval_t4'\n",
        "print('Tanks & Temples:', TAT_DIR)\n",
        "print('Deep Blending  :', DB_DIR)\n",
        "print('Output         :', OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yt2H_Wh3ijvJ"
      },
      "outputs": [],
      "source": [
        "# Clone repo & install dependencies (single consolidated cell)\n",
        "%cd /content\n",
        "!git clone --recursive https://github.com/DanielCob/accesible-gaussian-splatting.git\n",
        "%cd /content/accesible-gaussian-splatting\n",
        "\n",
        "# Core Python deps\n",
        "!pip install -q plyfile\n",
        "!pip install -q ./submodules/diff-gaussian-rasterization\n",
        "!pip install -q ./submodules/simple-knn\n",
        "\n",
        "# System packages (COLMAP, ImageMagick, xvfb) for conversion & rendering\n",
        "!apt-get update -y\n",
        "!apt-get install -y colmap imagemagick xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yy16JmS2ImB"
      },
      "outputs": [],
      "source": [
        "# Run evaluation script (training + rendering + metrics at 7k)\n",
        "# NOTE: We only evaluate Tanks & Temples and Deep Blending (paper comparables)\n",
        "%cd /content/accesible-gaussian-splatting\n",
        "!python full_eval.py -tat \"{TAT_DIR}\" -db \"{DB_DIR}\" --output_path \"{OUTPUT_DIR}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PlkC7QW2ImC"
      },
      "outputs": [],
      "source": [
        "# Summarize metrics from results.json files\n",
        "import os, json, glob\n",
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for scene_dir in sorted(glob.glob(os.path.join(OUTPUT_DIR, '*'))):\n",
        "    results_path = os.path.join(scene_dir, 'results.json')\n",
        "    if os.path.isfile(results_path):\n",
        "        with open(results_path, 'r') as f:\n",
        "            data = json.load(f)  # {method: {SSIM, PSNR, LPIPS}}\n",
        "        for method, metrics in data.items():\n",
        "            rows.append({\n",
        "                'scene': os.path.basename(scene_dir),\n",
        "                'method': method,\n",
        "                'SSIM': metrics.get('SSIM'),\n",
        "                'PSNR': metrics.get('PSNR'),\n",
        "                'LPIPS': metrics.get('LPIPS'),\n",
        "            })\n",
        "df = pd.DataFrame(rows)\n",
        "if not df.empty:\n",
        "    df = df.sort_values(['scene','method']).reset_index(drop=True)\n",
        "    print(df.to_string(index=False))\n",
        "    summary_csv = os.path.join(OUTPUT_DIR, 'summary_metrics.csv')\n",
        "    df.to_csv(summary_csv, index=False)\n",
        "    print('\\nSaved summary to', summary_csv)\n",
        "else:\n",
        "    print('No results found under', OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9hhWqB-2ImC"
      },
      "outputs": [],
      "source": [
        "# Copy results back to Drive and also create a zip\n",
        "import shutil, os\n",
        "\n",
        "drive_out = '/content/drive/MyDrive/ag_splatting_eval/eval_t4'\n",
        "os.makedirs(os.path.dirname(drive_out), exist_ok=True)\n",
        "if os.path.exists(drive_out):\n",
        "    shutil.rmtree(drive_out)\n",
        "shutil.copytree(OUTPUT_DIR, drive_out)\n",
        "print('Copied eval results to', drive_out)\n",
        "\n",
        "zip_path = drive_out + '.zip'\n",
        "if os.path.exists(zip_path):\n",
        "    os.remove(zip_path)\n",
        "shutil.make_archive(drive_out, 'zip', OUTPUT_DIR)\n",
        "print('Zipped results at', zip_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}